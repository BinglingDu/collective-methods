######Scraping all the anchor tags from http://number27.org/works

<pre>
from bs4 import BeautifulSoup
import urllib.request

url = 'http://number27.org/works'
page = urllib.request.urlopen(url)
soup = BeautifulSoup(page.read())
links = soup.find_all('a')

for link in links:
    linkText = link.text or ''
    linkTextMod = ' '.join(linkText.split())
    linkHref = link.get('href') or ''
    linkHrefMod = linkHref.strip()
    print(linkTextMod + ' | ' + linkHrefMod)
</pre>

#####Scraping all the img links from https://www.instagram.com/karliekloss/, but it didn't work???

<pre>
from bs4 import BeautifulSoup
import urllib.request

url = 'https://www.instagram.com/karliekloss/'
page = urllib.request.urlopen(url)
html = page.read()
soup = BeautifulSoup(html, "html.parser")

links = soup.find_all('img', class_="_icyx7")

for link in links:
	linkHref = link.get('src') or ''
	print('Link: ' + linkHref)
</pre>

#####Scraping all the img links from https://movie.douban.com/

<pre>
from bs4 import BeautifulSoup
import urllib.request

url = 'https://movie.douban.com/'
page = urllib.request.urlopen(url)
html = page.read()
soup = BeautifulSoup(html, "html.parser")
links = soup.find_all('img', src=True)

for link in links:
    print (link['src'])
</pre>

#####Scraping all the links from https://en.wikipedia.org/wiki/Hyperlink

<pre>
from bs4 import BeautifulSoup
import urllib.request

url = 'https://en.wikipedia.org/wiki/Hyperlink'
page = urllib.request.urlopen(url)
html = page.read()
soup = BeautifulSoup(html, "html.parser")

links = soup.find_all("a")
for link in links:
	linkHref = link.get('href') or ''
	print('Hyperlink: ' + linkHref)
</pre>
